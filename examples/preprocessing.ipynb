{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing with ```cause2e```\r\n",
    "This notebook shows examples of how ```cause2e``` can be used for preprocessing data. Preprocessing can be performed by the ```discovery.StructureLearner``` before learning the causal graph. Afterwards, the preprocessing steps can be imitated by the ```estimator.Estimator``` before estimating quantitative causal effects. If you know your way around packages like ```Pandas```, you can surely perform all the presented transformations without ```cause2e```. However, it has proven convenient to reduce the number of interfaces between different packages (leading to datatype mismatches etc.) by integrating a few basic steps as built-in methods of ```cause2e```'s classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from cause2e import path_mgr, discovery, estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up paths to data and output directories\n",
    "This step is conveniently handled by the ```PathManager``` class, which avoids having to wrestle with paths throughout the multistep causal analysis. If we want to perform the analysis in a directory ```'dirname'``` that contains ```'dirname/data'``` and ```'dirname/output'``` as subdirectories, we can also use ```PathManagerQuick``` for an even easier setup. The experiment name is used for generating output files with meaningful names, in case we want to study multiple scenarios (e.g. with varying model parameters). For this analysis, we use the sprinkler dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\r\n",
    "wd = os.path.dirname(cwd)\r\n",
    "paths = path_mgr.PathManagerQuick(experiment_name='sprinkler',\r\n",
    "                                  data_name='sprinkler.csv',\r\n",
    "                                  directory=wd\r\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the StructureLearner\n",
    "As in the other notebooks, we set up a ```StructureLearner``` and read our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = discovery.StructureLearner(paths)\n",
    "learner.read_csv(index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step in the analysis should be an assessment of which variables we are dealing with. In the sprinkler dataset, each sample tells us \n",
    "- the current season\n",
    "- whether it is raining\n",
    "- whether our lawn sprinkler is activated\n",
    "- whether our lawn is slippery\n",
    "- whether our lawn is wet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Season', 'Sprinkler', 'Wet', 'Rain', 'Slippery'}\n"
     ]
    }
   ],
   "source": [
    "print(learner.variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete a variable\n",
    "In case we are sure that a variable is not related to our quantities of interest, we can always delete it from the data. For demonstration purposes, let us remove the ```'Slippery'``` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Sprinkler', 'Wet', 'Rain', 'Season'}\n"
     ]
    }
   ],
   "source": [
    "learner.delete_variable('Slippery')\n",
    "print(learner.variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add a variable\n",
    "On the other hand, we might have a column of values from another data source that we want to add."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Season', 'Sprinkler', 'Wet', 'Rain', 'Fake_Slippery'}\n",
      "     Season  Sprinkler  Rain  Wet  Fake_Slippery\n",
      "0    Winter          0     0    0              0\n",
      "1    Winter          0     0    0              0\n",
      "2    Winter          0     1    1              0\n",
      "3    Autumn          0     1    1              0\n",
      "4    Summer          1     0    1              0\n",
      "..      ...        ...   ...  ...            ...\n",
      "995  Spring          1     1    1              0\n",
      "996  Spring          0     0    0              0\n",
      "997  Spring          0     1    1              0\n",
      "998  Summer          1     0    1              0\n",
      "999  Summer          1     1    1              0\n",
      "\n",
      "[1000 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# generate something to add\n",
    "n_samples = len(learner.data)\n",
    "fake_slippery = pd.DataFrame(([0] * n_samples))\n",
    "# add it to the data\n",
    "learner.add_variable('Fake_Slippery', fake_slippery)\n",
    "#check output\n",
    "print(learner.variables)\n",
    "print(learner.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rename a variable\n",
    "For more cleanliness, it can often be helpful to eliminate naming artefacts like prefixes from the variables. We demonstrate this by removing the prefix of the ```'Fake_Slippery'``` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Season', 'Sprinkler', 'Wet', 'Rain', 'Slippery'}\n"
     ]
    }
   ],
   "source": [
    "learner.rename_variable('Fake_Slippery', 'Slippery')\n",
    "print(learner.variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine variables into a new variable\n",
    "If we are not interested in the provided variables themselves, but in derived versions of them (e.g. deviations), we can use ```cause2e```'s functionality for combining variables into a new variable. Suppose that we are interested in the deviation of ```'Wet'``` from ```'Sprinkler'```, because we want to see if the sprinkler is the only reason for the lawn being wet. The ```'keep_old'``` argument indicates whether we want to keep the input columns in our data frame after we have created the new column from them. A look at the new column tells us that the information about the lawn being wet is not identical to the one in the ```'Sprinkler'``` column, so it might be a multicausal scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Season  Sprinkler  Rain  Wet  Slippery  Deviation_Wet_Sprinkler\n",
      "0    Winter          0     0    0         0                        0\n",
      "1    Winter          0     0    0         0                        0\n",
      "2    Winter          0     1    1         0                        1\n",
      "3    Autumn          0     1    1         0                        1\n",
      "4    Summer          1     0    1         0                        0\n",
      "..      ...        ...   ...  ...       ...                      ...\n",
      "995  Spring          1     1    1         0                        0\n",
      "996  Spring          0     0    0         0                        0\n",
      "997  Spring          0     1    1         0                        1\n",
      "998  Summer          1     0    1         0                        0\n",
      "999  Summer          1     1    1         0                        0\n",
      "\n",
      "[1000 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "def deviation(data, col1, col2):\n",
    "    return data[col1] - data[col2]\n",
    "\n",
    "learner.combine_variables(name='Deviation_Wet_Sprinkler',\n",
    "                          input_cols=['Wet', 'Sprinkler'],\n",
    "                          func=deviation,\n",
    "                          keep_old=True\n",
    "                          )\n",
    "\n",
    "print(learner.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize a variable\n",
    "If our data is measured on different scales (e.g. kilometres vs centimetres), normalization is a vital step. This can be achieved by a suitable call to the ```combine_variables``` method, but for convenience we have added z-score normalization as a separate method. This normalization ensures that the treated data column has mean 0 and standard deviation 1, which helps with putting all the variables on the same scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Season  Sprinkler  Rain  Wet  Slippery  Deviation_Wet_Sprinkler\n",
      "0    Winter  -0.725753     0    0         0                        0\n",
      "1    Winter  -0.725753     0    0         0                        0\n",
      "2    Winter  -0.725753     1    1         0                        1\n",
      "3    Autumn  -0.725753     1    1         0                        1\n",
      "4    Summer   1.377879     0    1         0                        0\n",
      "..      ...        ...   ...  ...       ...                      ...\n",
      "995  Spring   1.377879     1    1         0                        0\n",
      "996  Spring  -0.725753     0    0         0                        0\n",
      "997  Spring  -0.725753     1    1         0                        1\n",
      "998  Summer   1.377879     0    1         0                        0\n",
      "999  Summer   1.377879     1    1         0                        0\n",
      "\n",
      "[1000 rows x 6 columns]\n",
      "Sprinkler mean: -1.4210854715202004e-17\n",
      "Sprinkler standard deviation: 1.0005003753127735\n"
     ]
    }
   ],
   "source": [
    "learner.normalize_variable('Sprinkler')\n",
    "print(learner.data)\n",
    "print(f\"Sprinkler mean: {learner.data['Sprinkler'].mean(axis=0)}\")\n",
    "print(f\"Sprinkler standard deviation: {learner.data['Sprinkler'].std(axis=0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imitate preprocessing steps with the Estimator class\n",
    "Just like the ```StructureLearner```, the ```Estimator``` also has methods for reading data. Having two independent reading steps instead of passing the data directly comes in handy when we want to use different sample sizes for causal discovery and estimation, when we are dealing with big data that cannot be fully stored in RAM, or when we are dealing with two entirely different datasets that only have the qualitative graph structure in common."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "estim = estimator.Estimator(paths)\n",
    "estim.read_csv(index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A drawback of the approach with separate reading methods is that we lose all the preprocessing that has been applied by the ```StructureLearner```. Notice how e.g. ```'Sprinkler'``` is back in its original state before the normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Sprinkler</th>\n",
       "      <th>Rain</th>\n",
       "      <th>Wet</th>\n",
       "      <th>Slippery</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Winter</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Winter</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Winter</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Autumn</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Summer</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Spring</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Spring</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Spring</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Summer</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Summer</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Season  Sprinkler  Rain  Wet  Slippery\n",
       "0    Winter          0     0    0         0\n",
       "1    Winter          0     0    0         0\n",
       "2    Winter          0     1    1         1\n",
       "3    Autumn          0     1    1         1\n",
       "4    Summer          1     0    1         1\n",
       "..      ...        ...   ...  ...       ...\n",
       "995  Spring          1     1    1         1\n",
       "996  Spring          0     0    0         0\n",
       "997  Spring          0     1    1         1\n",
       "998  Summer          1     0    1         1\n",
       "999  Summer          1     1    1         1\n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estim.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we are dealing with the same samples for both the ```StructureLearner``` and the ```Estimator```, we can just assign ```estim.data = learner.data``` without having to worry about these issues. There is even a convenience constructor for this specific use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Season  Sprinkler  Rain  Wet  Slippery  Deviation_Wet_Sprinkler\n",
      "0    Winter  -0.725753     0    0         0                        0\n",
      "1    Winter  -0.725753     0    0         0                        0\n",
      "2    Winter  -0.725753     1    1         0                        1\n",
      "3    Autumn  -0.725753     1    1         0                        1\n",
      "4    Summer   1.377879     0    1         0                        0\n",
      "..      ...        ...   ...  ...       ...                      ...\n",
      "995  Spring   1.377879     1    1         0                        0\n",
      "996  Spring  -0.725753     0    0         0                        0\n",
      "997  Spring  -0.725753     1    1         0                        1\n",
      "998  Summer   1.377879     0    1         0                        0\n",
      "999  Summer   1.377879     1    1         0                        0\n",
      "\n",
      "[1000 rows x 6 columns]\n",
      "Data identical to data of the StructureLearner: True\n"
     ]
    }
   ],
   "source": [
    "estim_2 = estimator.Estimator.from_learner(learner, same_data=True)\r\n",
    "print(estim_2.data)\r\n",
    "print(f\"Data identical to data of the StructureLearner: {estim_2.data.equals(learner.data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, if the data for the estimation part consists of different (or just more) samples, this approach is not possible. Luckily, the ```StructureLearner``` stores all its preprocessing steps in its ```transformations``` attribute. We implicitly pass it at the initialization of the ```Estimator``` so that we can easily transform the new samples in the same way.\r\n",
    "\r\n",
    "The only thing that we need to provide additionally is an ordered list of columns that should be used in the ```add_variable``` steps of the preprocessing, since storing the original columns is generally not a good idea with big data.\r\n",
    "\r\n",
    "If you run into any problems, please make sure that you have performed each preprocessing step with the ```StructureLearner``` only once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Season  Sprinkler  Rain  Wet  Slippery  Deviation_Wet_Sprinkler\n",
      "0    Winter  -0.725753     0    0         0                        0\n",
      "1    Winter  -0.725753     0    0         0                        0\n",
      "2    Winter  -0.725753     1    1         0                        1\n",
      "3    Autumn  -0.725753     1    1         0                        1\n",
      "4    Summer   1.377879     0    1         0                        0\n",
      "..      ...        ...   ...  ...       ...                      ...\n",
      "995  Spring   1.377879     1    1         0                        0\n",
      "996  Spring  -0.725753     0    0         0                        0\n",
      "997  Spring  -0.725753     1    1         0                        1\n",
      "998  Summer   1.377879     0    1         0                        0\n",
      "999  Summer   1.377879     1    1         0                        0\n",
      "\n",
      "[1000 rows x 6 columns]\n",
      "Data identical to data of the StructureLearner: True\n"
     ]
    }
   ],
   "source": [
    "# create new Estimator\r\n",
    "estim_3 = estimator.Estimator.from_learner(learner)\r\n",
    "estim_3.read_csv(index_col=0)\r\n",
    "# replicate preprocessing steps from StructureLearner\r\n",
    "vals_list = [fake_slippery]\r\n",
    "estim_3.imitate_data_trafos(vals_list)\r\n",
    "# check results\r\n",
    "print(estim_3.data)\r\n",
    "print(f\"Data identical to data of the StructureLearner: {estim_3.data.equals(learner.data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the ```Estimator``` now has the data in the same format as the ```StructureLearner```. This is vital for any subsequent analysis, since the data of the ```StructureLearner``` is used to learn a causal graph which then serves to guide the ```Estimator``` in performing the right estimation steps. If the variables do not match, we will most likely run into problems."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4697cb428b990343430888fd6e79b9ccd4a789c087a3fcc20700e77261b659ed"
  },
  "kernelspec": {
   "display_name": "Python 3.7.1 64-bit ('test': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}